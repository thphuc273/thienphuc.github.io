[{"content":"‚úèÔ∏è Intro If you‚Äôre like me who loves reading books on Kindle, you might have wondered how you could extract your highlights in an organized way and save them as notes. At least I did. You see, I use Notion as my primary note-taking/productivity management app and I already have a database of all the books that I have read so far and also the ones that I am planning to read next.\nAnd since each of these book entries in the Notion database is a page in itself, I thought why not populate them with the highlights that I made in Kindle while reading them. The only problem was Kindle stores all of the highlights in a text file (My Clippings.txt) which as you can see contains a tonne of useless information like the book location, where the highlight was made, and when it was made.\nI needed to find a way to filter out the highlights, group them by the book title and send them to my Notion book database. Not only that, all of this should happen automatically with minimal human effort. So, over the past two weekends, I spent the majority of my time coding and I‚Äôm finally ready with an app that would allow readers to seamlessly transfer all of their highlights to Notion. Let‚Äôs take a look\u0026hellip;\nü§ñ Node Environment You need a stable version of Node JS, installed locally, to run this app. I have tested this on Node versions 16 and 14, and it has worked flawlessly on both of them. So, before proceeding to the next steps, make sure you have a stable version of Node installed. I‚Äôm not going to explain the environment setup in this article because the installation process might differ for different operating systems. You can easily learn that on Google.\n‚öôÔ∏è Setup Follow the steps given below to set up the Kindle to Notion app on your local system.\nCopy my Books Database Template to your Notion dashboard. The app requires some fields (Title, Author, and Book Name) to be present in the database in order for the highlight sync to work properly. So, you can either create your own database having these fields or you can just copy mine using the template I provided above.\nClone the GitHub Repository to your local system and install the dependencies.\ngit clone https://github.com/arkalim/kindle-to-notion.git cd kindle-to-notion npm install Rename these files or folders by removing .example extensions as shown below. The original files/folders in my local repo contained data that was either sensitive or specific to my highlights. So, I created empty aliases of them with .example extensions and committed them to GitHub.\n‚Ä£ cache.example ‚û° cache\n‚Ä£ data.example ‚û° data\n‚Ä£ .env.example ‚û° .env\nGet your Notion API key at the Notion Integrations page and create a new internal integration. Integrations allow us to access a portion of our Notion workspace using a secret token called the Notion API key (Internal Integration Token).\nGo to your Notion dashboard. Navigate to the Books database. Click on Share in the top right-hand corner and invite the integration you just created. This will allow the integration to edit the Books database using the Notion API key that we got in the previous step. Copy the link to the Notion Books database and extract the Database Id as shown below. The database id is nothing but all of the gibberish between the last / and the ?. This is required by the app to perform CRUD operations on this database. Original Link: https://www.notion.so/arkalim/346be84507ff482b80fceb4024deadc2?v=e868075eaf5749bc941e617e651295fb Database Id: 346be84507ff482b80fceb4024deadc2 So, now you have the Notion API key as well as the Database Id. Now, populate these variables in the .env file. Storing this sensitive information in .env ensures that it won‚Äôt get exposed to the rest of the world if you commit your local repo to GitHub as .gitignore has been configured to ignore .env during commits. NOTION_API_KEY=your-notion-api-key BOOK_DB_ID=your-book-database-id Connect your Kindle to your computer. Navigate to Kindle ‚û° documents and copy My Clippings.txt. Replace my My Clippings.txt in resources folder with yours. üîÅ Sync Highlights Finally, we are at the end of the setup section. You are now ready to sync your Kindle highlights to Notion. Open a terminal in your local repository and run the following command to watch your highlights teleport!\nnpm start ‚ùóÔ∏èFor Nerds Every highlight made on Kindle is appended at the end of My Clippings.txt. RegEx has been used extensively throughout the application to parse and filter this text file. cache is a folder that contains the local cache to prevent the app from resyncing old highlights. data is a folder that contains the API response logs. .env is a file containing the environment variables like the Notion API key and the Database Id. Book Name is used as the primary key to facilitate upsert operation in the Notion database. Book Name corresponds to the title of the book in My Clippings.txt. So, this field should be left untouched. However, the other fields like Title, Author, Date Started, Date Finished, Status, and Genre could be modified as per your wish. The app maintains a local cache in the file sync.json present in the cache folder. This JSON file is updated at the end of each sync. This is done to prevent the app from resyncing the old highlights. If no new highlights have been made, no sync takes place. In case you wish to sync every book all over again, you need to empty the array present in sync.json and delete all the highlights present in your Notion database before running the sync. Responses from Notion API calls are exported to files with .json extensions in data folder. This was done to mitigate the problem of effectively logging JSON objects in the console (terminal). That‚Äôs all folks! If you made it till here, hats off to you! In this article, we learned how to set up Kindle to Notion app on our local system and use it to sync our Kindle highlights to the Notion Books database. If you want me to write more detailed articles explaining the inner workings of this app, drop a comment below. I write articles regularly so you should consider following me to get more such articles in your feed. Thanks a lot for reading!\n","permalink":"https://thphuc273.github.io/blog/test/","summary":"\u003ch1 id=\"-intro\"\u003e‚úèÔ∏è Intro\u003c/h1\u003e\n\u003cp\u003eIf you‚Äôre like me who loves reading books on Kindle, you might have wondered how you could extract your highlights in an organized way and save them as notes. At least I did. You see, I use Notion as my primary note-taking/productivity management app and I already have a database of all the books that I have read so far and also the ones that I am planning to read next.\u003c/p\u003e","title":"Kindle to Notion"},{"content":"","permalink":"https://thphuc273.github.io/projects/test/","summary":"","title":"Example project"},{"content":" üëã About Me Hi, I\u0026rsquo;m Felix ‚Äî a fresh graduate Information Technology student at the University of Science, VNU-HCM, with a strong passion for Machine Learning, Deep Learning, and Model Interpretability.\nOver the past few years, I\u0026rsquo;ve been exploring the power of intelligent systems to solve real-world problems, from NLP model interpretability to student performance prediction and medical image segmentation. My goal is to build AI systems that are not only powerful, but also explainable and trustworthy.\nüî¨ My Research \u0026amp; Interests Model Interpretability \u0026amp; Privacy:\nI recently conducted a thesis on ‚ÄúDetermining and erasing knowledge neurons in Transformer models‚Äù, exploring how to selectively forget specific facts in BERT without hurting its overall performance ‚Äî a growing area of interest in responsible AI.\nEnd-to-End ML Applications:\nI‚Äôve built and deployed multiple machine learning applications using Flask, AWS, and CI/CD pipelines ‚Äî turning models into real-world products.\nComputer Vision \u0026amp; NLP:\nFrom blood cell segmentation with YOLOv9-Seg to relational fact erasure in Transformers, I enjoy tackling both structured and unstructured data challenges.\nüß∞ Tech Stack Languages \u0026amp; Frameworks: Python, PyTorch, NumPy, Pandas, Matplotlib Web \u0026amp; Cloud: Flask, AWS Elastic Beanstalk, CodePipeline MLOps: Git, CI/CD, Terraform (basic), Docker (basic) Visualization: PowerBI, Tableau Currently exploring: LangChain, Streamlit, MLflow, Kubernetes üéØ My Mission I believe in the power of AI to create real impact ‚Äî but also in the responsibility to build systems that are interpretable, fair, and human-centered.\nWhether it‚Äôs tuning a regression model, deploying a segmentation app, or digging into the ‚Äúneurons‚Äù of a Transformer, I‚Äôm always curious, always learning, and always aiming to build something meaningful.\n","permalink":"https://thphuc273.github.io/about/","summary":"\u003cimg src=\"/images/phuc.png\" alt=\"avatar\" width=\"150\" style=\"border-radius: 50%; margin-bottom: 1rem;\"\u003e\n\u003ch2 id=\"-about-me\"\u003eüëã About Me\u003c/h2\u003e\n\u003cp\u003eHi, I\u0026rsquo;m Felix ‚Äî a fresh graduate Information Technology student at the University of Science, VNU-HCM, with a strong passion for Machine Learning, Deep Learning, and Model Interpretability.\u003c/p\u003e\n\u003cp\u003eOver the past few years, I\u0026rsquo;ve been exploring the power of intelligent systems to solve real-world problems, from NLP model interpretability to student performance prediction and medical image segmentation. My goal is to build AI systems that are not only powerful, but also explainable and trustworthy.\u003c/p\u003e","title":"About"}]